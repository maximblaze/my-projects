{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Работа выполнена Доронькиным Максимом. Некоторые части программы основаны на baseline решении на Stepik.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi\nimport torch\ntorch.cuda.is_available()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport random\nfrom skimage import io\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom PIL import Image\nfrom pathlib import Path\n\nfrom torchvision import transforms\nfrom multiprocessing.pool import ThreadPool\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\n\nfrom matplotlib import colors, pyplot as plt\n%matplotlib inline\n\n# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n# мы будем игнорировать warnings\nimport warnings\nwarnings.filterwarnings(action='ignore', category=DeprecationWarning)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 100\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# разные режимы датасета \nDATA_MODES = ['train', 'val', 'test']\n# все изображения будут масштабированы к размеру 224x224 px\nRESCALE_SIZE = 224\n# работаем на видеокарте\nDEVICE = torch.device(\"cuda\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SimpsonsDataset(Dataset):\n    \"\"\"\n    Датасет с картинками, который паралельно подгружает их из папок\n    производит скалирование и превращение в торчевые тензоры\n    \"\"\"\n    def __init__(self, files, mode):\n        super().__init__()\n        # список файлов для загрузки\n        self.files = sorted(files)\n        # режим работы\n        self.mode = mode\n\n        if self.mode not in DATA_MODES:\n            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n            raise NameError\n\n        self.len_ = len(self.files)\n     \n        self.label_encoder = LabelEncoder()\n\n        if self.mode != 'test':\n            self.labels = [path.parent.name for path in self.files]\n            self.label_encoder.fit(self.labels)\n\n            with open('label_encoder.pkl', 'wb') as le_dump_file:\n                  pickle.dump(self.label_encoder, le_dump_file)\n                      \n    def __len__(self):\n        return self.len_\n      \n    def load_sample(self, file):\n        image = Image.open(file)\n        image.load()\n        return image\n  \n    def __getitem__(self, index):\n        # введем тут наши аугментации для train и val/test данных. \n        \n        if self.mode == 'train': \n            transform = transforms.Compose([\n                transforms.Resize(size=(RESCALE_SIZE, RESCALE_SIZE)),\n                transforms.RandomRotation(degrees=45),\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomVerticalFlip(p=0.25),\n                transforms.ColorJitter(hue=.1, saturation=.1),\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n            ])\n        else:\n            transform = transforms.Compose([\n                transforms.Resize(size=(RESCALE_SIZE, RESCALE_SIZE)),\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n            ])\n        x = self.load_sample(self.files[index])\n        x = transform(x)\n        if self.mode == 'test':\n            return x\n        else:\n            label = self.labels[index]\n            label_id = self.label_encoder.transform([label])\n            y = label_id.item()\n            return x, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(inp, title=None, plt_ax=plt, default=False):\n    \"\"\"Imshow для тензоров\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt_ax.imshow(inp)\n    if title is not None:\n        plt_ax.set_title(title)\n    plt_ax.grid(False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = Path('/kaggle/input/journey-springfield/train/simpsons_dataset')\nTEST_DIR = Path('/kaggle/input/journey-springfield/testset/testset')\n\ntrain_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\ntest_files = sorted(list(TEST_DIR.rglob('*.jpg')))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_val_labels = [path.parent.name for path in train_val_files]\ntrain_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n                                          stratify=train_val_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = SimpsonsDataset(train_files, mode='train')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"БЛОК ПРЕДОБРАБОТКИ ПАПКИ ТРЕНИРОВКИ. Дело в том, что наши данные очень плохо сбалансированы. Гомера Симпсона очень много, а вот некоторых персонажей всего по 3-4 картинки, значит сеть будет их забывать, ибо очень редко будет видеть, так что напишем код, чтобы их размножить. Многое в этом коде есть в открытых комментариях Stepik.","metadata":{}},{"cell_type":"code","source":"def create_dct_path_labels(train_files, train_labels):\n    dct_simpsons = {}\n    for label_i in np.unique(train_labels).tolist():\n        dct_simpsons[label_i] = []\n\n    for path_i, label_i in zip(train_files, train_labels):\n        dct_simpsons[label_i].append(path_i)\n\n    return dct_simpsons\n\n# Создадим словарь в котором ключами будут персонажи Симпсонов, а значениями списки с путями к картинкам.\ndct_path_train = create_dct_path_labels(train_files, train_dataset.labels)\n\n# Расширяем классы с менее 100 картинками до 120 картинок в классе. Не будем ставить больше, чтобы не перегружать GPU в будущем\nfor person in dct_path_train:\n    if len(dct_path_train[person]) < 100:\n        dct_path_train[person] = dct_path_train[person] * (100 // len(dct_path_train[person]))\n        dct_path_train[person].extend(dct_path_train[person][:100 - len(dct_path_train[person])])\n# Проверим что получилось \nfor person in dct_path_train:\n    print(f\"{person}\\t{len(dct_path_train[person])}\")\nnew_train_files = []\n\nfor person in dct_path_train:\n    new_train_files.extend(dct_path_train[person])\n\nval_dataset = SimpsonsDataset(val_files, mode='val')\nnew_train_dataset = SimpsonsDataset(new_train_files, mode='train')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = new_train_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = val_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_epoch(model, train_loader, criterion, optimizer):\n    running_loss = 0.0\n    running_corrects = 0\n    processed_data = 0\n  \n    for inputs, labels in train_loader:\n        inputs = inputs.to(DEVICE)\n        labels = labels.to(DEVICE)\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        preds = torch.argmax(outputs, 1)\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_data += inputs.size(0)\n              \n    train_loss = running_loss / processed_data\n    train_acc = running_corrects.cpu().numpy() / processed_data\n    return train_loss, train_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_epoch(model, val_loader, criterion, min_loss, eps, model_name):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    processed_size = 0\n    for inputs, labels in tqdm(val_loader):\n        inputs = inputs.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        with torch.set_grad_enabled(False):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            preds = torch.argmax(outputs, 1)\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        processed_size += inputs.size(0)\n    #этот блок нужен для того, чтобы сохранять только самую лучшую модель по лоссу на валидации\n    val_loss = running_loss / processed_size\n    if val_loss < min_loss or val_loss == min_loss+eps:\n        torch.save(model.state_dict(), model_name)\n    val_acc = running_corrects.double() / processed_size\n    return val_loss, val_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(train_files, val_files, model, epochs, batch_size, model_name):\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=8, shuffle=False)\n\n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n\n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        opt = torch.optim.AdamW(model.parameters(), lr=0.001)  \n        scheduler = torch.optim.lr_scheduler.StepLR(opt, 2, 0.5) #введём scheduler чтобы уменьшать learning rate динамически во время обучения\n        criterion = nn.CrossEntropyLoss()\n        min_loss = np.inf\n        eps = 0.001\n        for epoch in range(epochs):\n            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n            print(\"loss\", train_loss)\n            \n            val_loss, val_acc = eval_epoch(model, val_loader, criterion, min_loss, eps, model_name)\n            history.append((train_loss, train_acc, val_loss, val_acc))\n            scheduler.step()\n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n\n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, test_loader):\n    with torch.no_grad():\n        logits = []\n    \n        for inputs in test_loader:\n            inputs = inputs.to(DEVICE)\n            model.eval()\n            outputs = model(inputs).cpu()\n            logits.append(outputs)\n            \n    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n    return probs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В качестве рабочей модели будем использовать новшество последнего времени, разрывающее ImageNette - Efficient Net, её ещё нет в torch, поэтому загружаем её со специального github репозитория. \nGithub link:https://github.com/lukemelas/EfficientNet-PyTorch/tree/master/efficientnet_pytorch","metadata":{}},{"cell_type":"code","source":"pip install efficientnet_pytorch ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\nefficient_model_1 = EfficientNet.from_pretrained('efficientnet-b0')\nefficient_model_1.fc = nn.Linear(1280, 42)  #модифицируем только fc слой, сделав выход на 42 класса, так как столько у нас Симпсонов, остальные слои оставляем предобученными.\nefficient_model_1.to(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64  #установим размер батча 64","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Наконец, обучение 10 эпох efficient net на нашем датасете!","metadata":{}},{"cell_type":"code","source":"history_1 = train(new_train_dataset, val_dataset, model=efficient_model_1, epochs=15, batch_size=batch_size, model_name='efficient_net_1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\nefficient_model_2 = EfficientNet.from_pretrained('efficientnet-b0')\nefficient_model_2.fc = nn.Linear(1280, 42)  #модифицируем только fc слой, сделав выход на 42 класса, так как столько у нас Симпсонов, остальные слои оставляем предобученными.\nefficient_model_2.to(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_2(train_files, val_files, model, epochs, batch_size, model_name):\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=8, shuffle=False)\n\n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n\n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        opt = torch.optim.AdamW(model.parameters(), lr=0.001)  \n        scheduler = torch.optim.lr_scheduler.StepLR(opt, 3, 0.5) #введём scheduler чтобы уменьшать learning rate динамически во время обучения\n        criterion = nn.CrossEntropyLoss()\n        min_loss = np.inf\n        eps = 0.001\n        for epoch in range(epochs):\n            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n            print(\"loss\", train_loss)\n            \n            val_loss, val_acc = eval_epoch(model, val_loader, criterion, min_loss, eps, model_name)\n            history.append((train_loss, train_acc, val_loss, val_acc))\n            scheduler.step()\n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n\n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_2 = train_2(new_train_dataset, val_dataset, model=efficient_model_2, epochs=15, batch_size=batch_size*2, model_name='efficient_net_2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"А теперь загрузим сохраненную нами НАИЛУЧШУЮ версию по лоссу на валидации модели efficient net:","metadata":{}},{"cell_type":"code","source":"# загружаем веса обученные на наших Симпсонах\nefficient_model_1.load_state_dict(torch.load(\"efficient_net_1\"))\nefficient_model_2.load_state_dict(torch.load(\"efficient_net_2\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Ensemble(nn.Module):   \n    def __init__(self, modelA, modelB):\n        super(Ensemble, self).__init__()\n        self.modelA = modelA\n        self.modelB = modelB\n\n        self.classifier = nn.Linear(42 * 2, 42)\n        \n    def forward(self, x):\n        x1 = self.modelA(x)\n        x2 = self.modelB(x)\n    \n        x = torch.cat((x1, x2), dim=1)\n        \n        x = self.classifier(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Ensemble = Ensemble(efficient_model_1, efficient_model_2).to(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in Ensemble.parameters():\n    param.requires_grad = False\n\nfor param in Ensemble.classifier.parameters():\n    param.requires_grad = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_3 = train(new_train_dataset, val_dataset, model=Ensemble, epochs=10, batch_size=batch_size, model_name='ensemble')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Ensemble.load_state_dict(torch.load(\"ensemble\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ну и что теперь со всем этим делать?","metadata":{}},{"cell_type":"markdown","source":"Хорошо бы понять, как сделать сабмит. У нас есть сеть и методы eval у нее, которые позволяют перевести сеть в режим предсказания. Стоит понимать, что у нашей модели на последнем слое стоит softmax, которые позволяет получить вектор вероятностей того, что объект относится к тому или иному классу. Давайте воспользуемся этим.","metadata":{}},{"cell_type":"code","source":"def predict_one_sample(model, inputs, device=DEVICE):\n    \"\"\"Предсказание, для одной картинки\"\"\"\n    with torch.no_grad():\n        inputs = inputs.to(device)\n        model.eval()\n        logit = model(inputs).cpu()\n        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n    return probs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_characters = int(np.random.uniform(0,1000))\nex_img, true_label = val_dataset[random_characters]\nprobs_im_1 = predict_one_sample(efficient_model_1, ex_img.unsqueeze(0))\nprobs_im_2 = predict_one_sample(efficient_model_2, ex_img.unsqueeze(0))\n#probs_im_3 = predict_one_sample(Ensemble, ex_img.unsqueeze(0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idxs = list(map(int, np.random.uniform(0,1000, 20)))\nimgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n\nprobs_ims_1 = predict(efficient_model_1, imgs)\nprobs_ims_2 = predict(efficient_model_2, imgs)\n#probs_ims_3 = predict(Ensemble, imgs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_1 = np.argmax(probs_ims_1,-1)\ny_pred_2 = np.argmax(probs_ims_2,-1)\n#y_pred_3 = np.argmax(probs_ims_3,-1)\n\nactual_labels = [val_dataset[id][1] for id in idxs]\n\npreds_class_1 = [label_encoder.classes_[i] for i in y_pred_1]\npreds_class_2 = [label_encoder.classes_[i] for i in y_pred_2]\n#preds_class_3 = [label_encoder.classes_[i] for i in y_pred_3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Обратите внимание, что метрика, которую необходимо оптимизировать в конкурсе --- f1-score. Вычислим целевую метрику на валидационной выборке.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nprint(f1_score(actual_labels, y_pred_1, average='micro'))\nprint(f1_score(actual_labels, y_pred_2, average='micro'))\n#print(f1_score(actual_labels, y_pred_3, average='micro'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Полученная F_1 score нас бесспорно устраивает!","metadata":{}},{"cell_type":"markdown","source":"Сделаем классную визуализацию, чтобы посмотреть насколько сеть уверена в своих ответах. Можете исспользовать это, чтобы отлаживать правильность вывода.\n","metadata":{}},{"cell_type":"markdown","source":"import matplotlib.patches as patches\nfrom matplotlib.font_manager import FontProperties\n\nfig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n                        sharey=True, sharex=True)\nfor fig_x in ax.flatten():\n    random_characters = int(np.random.uniform(0,1000))\n    im_val, label = val_dataset[random_characters]\n    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n    \n    \n\n    imshow(im_val.data.cpu(), \\\n          title=img_label,plt_ax=fig_x)\n    \n    actual_text = \"Actual : {}\".format(img_label)\n            \n    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n    font0 = FontProperties()\n    font = font0.copy()\n    font.set_family(\"fantasy\")\n    prob_pred = predict_one_sample(efficient_model, im_val.unsqueeze(0))\n    predicted_proba = np.max(prob_pred)*100\n    y_pred = np.argmax(prob_pred)\n    \n    predicted_label = label_encoder.classes_[y_pred]\n    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n            \n    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')","metadata":{"trusted":true}},{"cell_type":"markdown","source":"Сеть идеально уверена в своих ответах!","metadata":{}},{"cell_type":"markdown","source":"# **Submit на Kaggle**","metadata":{}},{"cell_type":"code","source":"test_dataset = SimpsonsDataset(test_files, mode=\"test\")\ntest_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\nprobs_1 = predict(efficient_model_1, test_loader)\nprobs_2 = predict(efficient_model_2, test_loader)\nprobs_3 = predict(Ensemble, test_loader)\n\npreds_1 = label_encoder.inverse_transform(np.argmax(probs_1, axis=1))\npreds_2 = label_encoder.inverse_transform(np.argmax(probs_2, axis=1))\npreds_3 = label_encoder.inverse_transform(np.argmax(probs_3, axis=1))\n\ntest_filenames = [path.name for path in test_dataset.files]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! ls ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Создаем data frame для submitа","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nmy_submit_1 = pd.DataFrame({'Id': test_filenames, 'Expected': preds_1})\nmy_submit_1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nmy_submit_2 = pd.DataFrame({'Id': test_filenames, 'Expected': preds_2})\nmy_submit_2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nmy_submit_3 = pd.DataFrame({'Id': test_filenames, 'Expected': preds_3})\nmy_submit_3.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"НУ И ФИНАЛЬНЫЙ CSV ФАЙЛ НА САБМИТ!!!","metadata":{}},{"cell_type":"code","source":"my_submit_1.to_csv('efficient_model_1_submit.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submit_2.to_csv('efficient_model_2_submit.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submit_3.to_csv('Ensemble_submit.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}